/*
 * DO NOT EDIT.
 *
 * Generated by the protocol buffer compiler.
 * Source: orderer/kafka.proto
 *
 */

// 
// Copyright IBM Corp. 2016 All Rights Reserved.
// 
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// 
// http://www.apache.org/licenses/LICENSE-2.0
// 
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that your are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _1: SwiftProtobuf.ProtobufAPIVersion_1 {}
  typealias Version = _1
}

///   KafkaMessage is a wrapper type for the messages
///   that the Kafka-based orderer deals with.
struct Orderer_KafkaMessage: SwiftProtobuf.Proto3Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = "KafkaMessage"
  static let protoPackageName: String = "orderer"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "regular"),
    2: .unique(proto: "time_to_cut", json: "timeToCut"),
    3: .same(proto: "connect"),
  ]

  private class _StorageClass {
    var _type: Orderer_KafkaMessage.OneOf_Type?

    init() {}

    func copy() -> _StorageClass {
      let clone = _StorageClass()
      clone._type = _type
      return clone
    }
  }

  private var _storage = _StorageClass()

  private mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _storage.copy()
    }
    return _storage
  }

  var regular: Orderer_KafkaMessageRegular {
    get {
      if case .regular(let v)? = _storage._type {
        return v
      }
      return Orderer_KafkaMessageRegular()
    }
    set {
      _uniqueStorage()._type = .regular(newValue)
    }
  }

  var timeToCut: Orderer_KafkaMessageTimeToCut {
    get {
      if case .timeToCut(let v)? = _storage._type {
        return v
      }
      return Orderer_KafkaMessageTimeToCut()
    }
    set {
      _uniqueStorage()._type = .timeToCut(newValue)
    }
  }

  var connect: Orderer_KafkaMessageConnect {
    get {
      if case .connect(let v)? = _storage._type {
        return v
      }
      return Orderer_KafkaMessageConnect()
    }
    set {
      _uniqueStorage()._type = .connect(newValue)
    }
  }

  var type: OneOf_Type? {
    get {return _storage._type}
    set {
      _uniqueStorage()._type = newValue
    }
  }

  enum OneOf_Type: Equatable {
    case regular(Orderer_KafkaMessageRegular)
    case timeToCut(Orderer_KafkaMessageTimeToCut)
    case connect(Orderer_KafkaMessageConnect)

    static func ==(lhs: Orderer_KafkaMessage.OneOf_Type, rhs: Orderer_KafkaMessage.OneOf_Type) -> Bool {
      switch (lhs, rhs) {
      case (.regular(let l), .regular(let r)): return l == r
      case (.timeToCut(let l), .timeToCut(let r)): return l == r
      case (.connect(let l), .connect(let r)): return l == r
      default: return false
      }
    }

    fileprivate init?<T: SwiftProtobuf.Decoder>(byDecodingFrom decoder: inout T, fieldNumber: Int) throws {
      switch fieldNumber {
      case 1:
        var value: Orderer_KafkaMessageRegular?
        try decoder.decodeSingularMessageField(value: &value)
        if let value = value {
          self = .regular(value)
          return
        }
      case 2:
        var value: Orderer_KafkaMessageTimeToCut?
        try decoder.decodeSingularMessageField(value: &value)
        if let value = value {
          self = .timeToCut(value)
          return
        }
      case 3:
        var value: Orderer_KafkaMessageConnect?
        try decoder.decodeSingularMessageField(value: &value)
        if let value = value {
          self = .connect(value)
          return
        }
      default:
        break
      }
      return nil
    }

    fileprivate func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V, start: Int, end: Int) throws {
      switch self {
      case .regular(let v):
        if start <= 1 && 1 < end {
          try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
        }
      case .timeToCut(let v):
        if start <= 2 && 2 < end {
          try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
        }
      case .connect(let v):
        if start <= 3 && 3 < end {
          try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
        }
      }
    }
  }

  init() {}

  mutating func _protobuf_generated_decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        try decodeField(decoder: &decoder, fieldNumber: fieldNumber)
      }
    }
  }

  mutating func _protobuf_generated_decodeField<D: SwiftProtobuf.Decoder>(decoder: inout D, fieldNumber: Int) throws {
    switch fieldNumber {
    case 1, 2, 3:
      if _storage._type != nil {
        try decoder.handleConflictingOneOf()
      }
      _storage._type = try Orderer_KafkaMessage.OneOf_Type(byDecodingFrom: &decoder, fieldNumber: fieldNumber)
    default: break
    }
  }

  func _protobuf_generated_traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      try _storage._type?.traverse(visitor: &visitor, start: 1, end: 4)
    }
  }

  func _protobuf_generated_isEqualTo(other: Orderer_KafkaMessage) -> Bool {
    return withExtendedLifetime((_storage, other._storage)) { (_storage, other_storage) in
      if _storage !== other_storage {
        if _storage._type != other_storage._type {return false}
      }
      return true
    }
  }
}

///   KafkaMessageRegular wraps a marshalled envelope.
struct Orderer_KafkaMessageRegular: SwiftProtobuf.Proto3Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = "KafkaMessageRegular"
  static let protoPackageName: String = "orderer"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "payload"),
  ]

  var payload: Data = Data()

  init() {}

  mutating func _protobuf_generated_decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      try decodeField(decoder: &decoder, fieldNumber: fieldNumber)
    }
  }

  mutating func _protobuf_generated_decodeField<D: SwiftProtobuf.Decoder>(decoder: inout D, fieldNumber: Int) throws {
    switch fieldNumber {
    case 1: try decoder.decodeSingularBytesField(value: &payload)
    default: break
    }
  }

  func _protobuf_generated_traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !payload.isEmpty {
      try visitor.visitSingularBytesField(value: payload, fieldNumber: 1)
    }
  }

  func _protobuf_generated_isEqualTo(other: Orderer_KafkaMessageRegular) -> Bool {
    if payload != other.payload {return false}
    return true
  }
}

///   KafkaMessageTimeToCut is used to signal to the orderers
///   that it is time to cut block <block_number>.
struct Orderer_KafkaMessageTimeToCut: SwiftProtobuf.Proto3Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = "KafkaMessageTimeToCut"
  static let protoPackageName: String = "orderer"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .unique(proto: "block_number", json: "blockNumber"),
  ]

  var blockNumber: UInt64 = 0

  init() {}

  mutating func _protobuf_generated_decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      try decodeField(decoder: &decoder, fieldNumber: fieldNumber)
    }
  }

  mutating func _protobuf_generated_decodeField<D: SwiftProtobuf.Decoder>(decoder: inout D, fieldNumber: Int) throws {
    switch fieldNumber {
    case 1: try decoder.decodeSingularUInt64Field(value: &blockNumber)
    default: break
    }
  }

  func _protobuf_generated_traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if blockNumber != 0 {
      try visitor.visitSingularUInt64Field(value: blockNumber, fieldNumber: 1)
    }
  }

  func _protobuf_generated_isEqualTo(other: Orderer_KafkaMessageTimeToCut) -> Bool {
    if blockNumber != other.blockNumber {return false}
    return true
  }
}

///   KafkaMessageConnect is posted by an orderer upon booting up.
///   It is used to prevent the panic that would be caused if we
///   were to consume an empty partition. It is ignored by all
///   orderers when processing the partition.
struct Orderer_KafkaMessageConnect: SwiftProtobuf.Proto3Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = "KafkaMessageConnect"
  static let protoPackageName: String = "orderer"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "payload"),
  ]

  var payload: Data = Data()

  init() {}

  mutating func _protobuf_generated_decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      try decodeField(decoder: &decoder, fieldNumber: fieldNumber)
    }
  }

  mutating func _protobuf_generated_decodeField<D: SwiftProtobuf.Decoder>(decoder: inout D, fieldNumber: Int) throws {
    switch fieldNumber {
    case 1: try decoder.decodeSingularBytesField(value: &payload)
    default: break
    }
  }

  func _protobuf_generated_traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !payload.isEmpty {
      try visitor.visitSingularBytesField(value: payload, fieldNumber: 1)
    }
  }

  func _protobuf_generated_isEqualTo(other: Orderer_KafkaMessageConnect) -> Bool {
    if payload != other.payload {return false}
    return true
  }
}

///   LastOffsetPersisted is the encoded value for the Metadata message
///   which is encoded in the ORDERER block metadata index for the case
///   of the Kafka-based orderer.
struct Orderer_KafkaMetadata: SwiftProtobuf.Proto3Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = "KafkaMetadata"
  static let protoPackageName: String = "orderer"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .unique(proto: "last_offset_persisted", json: "lastOffsetPersisted"),
  ]

  var lastOffsetPersisted: Int64 = 0

  init() {}

  mutating func _protobuf_generated_decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      try decodeField(decoder: &decoder, fieldNumber: fieldNumber)
    }
  }

  mutating func _protobuf_generated_decodeField<D: SwiftProtobuf.Decoder>(decoder: inout D, fieldNumber: Int) throws {
    switch fieldNumber {
    case 1: try decoder.decodeSingularInt64Field(value: &lastOffsetPersisted)
    default: break
    }
  }

  func _protobuf_generated_traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if lastOffsetPersisted != 0 {
      try visitor.visitSingularInt64Field(value: lastOffsetPersisted, fieldNumber: 1)
    }
  }

  func _protobuf_generated_isEqualTo(other: Orderer_KafkaMetadata) -> Bool {
    if lastOffsetPersisted != other.lastOffsetPersisted {return false}
    return true
  }
}
